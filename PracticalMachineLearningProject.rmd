Practical Machine Learning
=================================================================================
Final Project
------------------------------------
By Jeffrey Grossman
------------------------------------
11/19/2014
------------------------------------


For this project, data describing body movements and whether or not the specified execution of an exercise has been performed. This data is provided from the following source:
~~~~~~~
Ugulino, W.; Cardador, D.; Vega, K.; Velloso, E.; Milidiu, R.; Fuks, H. Wearable Computing: Accelerometers' Data Classification of Body Postures and Movements. Proceedings of 21st Brazilian Symposium on Artificial Intelligence. Advances in Artificial Intelligence - SBIA 2012. In: Lecture Notes in Computer Science. , pp. 52-61. Curitiba, PR: Springer Berlin / Heidelberg, 2012. ISBN 978-3-642-34458-9. DOI: 10.1007/978-3-642-34459-6_6. 
Cited by 2 (Google Scholar)
~~~~~~~
Using this data, a model will be built that places certain body movement measurements into different classes. One of these classes will describe the specified execution of an exercise while the other 4 classes will correspond to common mistakes made by participants. There are many different methods that can be used to predict whether or not the specified execution of an exercise has been performed or if it has been completed incorrectly. The machine learning methods that were considered were random forest, regression, and bagging. It was decided that random forest would build the most accurate model of this data set because it is a good method to use when there might exist several irrelevant factors. 

The following are the steps taken in R using the Caret package to train a model using Random Forest and predict the "classe" of the provided 20 test cases:

First the two provided CSV files were downloaded and read into R. A seed was set in order to make results reproducable.

~~~~~~~
train = read.csv("C:/users/jgrossman/documents/pml-training.csv",na.strings=c("NA",""),header=TRUE)
test = read.csv("C:/users/jgrossman/documents/pml-testing.csv",na.strings=c("NA",""),header=TRUE)
set.seed(100)
~~~~~~~

Next two lists of all of the column names of the train and test set were built.
~~~~~~~
trainColNames = colnames(train)
testColNames = colnames(test)
~~~~~~~

By viewing the data, it was determined that the first 8 columns should not be trained on. They included data such as date and time, which are irrelevant when it comes to prediction.
~~~~~~~
train = train[,8:length(trainColNames)]
test = test[,8:length(testColNames)]
~~~~~~~

By viewing the data it was clear that the majority of columns contained NA as a value. It was determined that these NA values would skew results so any column that contained an NA value was removed.
~~~~~~~
train = train[,! apply(train,2,function(x) any(is.na(x)))]
test = test[,! apply(test,2,function(x) any(is.na(x)))]
~~~~~~~

A test and train data set was created from the training CSV. It was decided that 70% of the training data should be used to train a random forest model and 30% would be used to test that model. 
~~~~~~~
myTrain = createDataPartition(y=train$classe, p=0.70,list=FALSE)
myTrainingData = train[myTrain,]
myTestingData = train[-myTrain,]
~~~~~~~

Next a Random Forest model was trained on the 70% training data. A repeated cross validation re-sampling method  with 5 folds and 4 repeated cross validations was used. When looking at the data output from the trained RF model, it was seen that an accuracy of about 99% was obtained on the training data. 
~~~~~~~
rfControl = trainControl(method="repeatedcv",number=5,repeats=5)
rfModel = train(myTrainingData$classe ~ ., method = "rf", trControl=rfControl,data=myTrainingData)
print(rfModel)
~~~~~~~
~~~~~~~
Random Forest 

13737 samples
   52 predictor
    5 classes: 'A', 'B', 'C', 'D', 'E' 

No pre-processing
Resampling: Cross-Validated (5 fold, repeated 5 times) 

Summary of sample sizes: 10990, 10990, 10989, 10989, 10990, 10990, ... 

Resampling results across tuning parameters:

  mtry  Accuracy   Kappa      Accuracy SD  Kappa SD   
   2    0.9894157  0.9866094  0.001877367  0.002376114
  27    0.9901581  0.9875490  0.001969213  0.002491415
  52    0.9847274  0.9806780  0.002882151  0.003647355

Accuracy was used to select the optimal model using  the largest value.
The final value used for the model was mtry = 27. 
~~~~~~~
Since only 70% of the training data was used to train the RF model, the 30% remaining can be used as an out of sample test for the RF model. The "classe" values for this testing set was predicted and compared to the actual results in a confusion matrix.  The results were showed about 99% accuracy. This result can also be used to declare that the model will provide an out of sample error of .61% using cross validation.
~~~~~~~
pred <- predict(rfModel, newdata=myTestingData)
print(confusionMatrix(pred,myTestingData$classe))
~~~~~~~
~~~~~~~
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1672    9    0    0    0
         B    1 1129    3    0    0
         C    0    1 1021   14    3
         D    0    0    2  950    2
         E    1    0    0    0 1077

Overall Statistics
                                          
               Accuracy : 0.9939          
                 95% CI : (0.9915, 0.9957)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.9923          
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9988   0.9912   0.9951   0.9855   0.9954
Specificity            0.9979   0.9992   0.9963   0.9992   0.9998
Pos Pred Value         0.9946   0.9965   0.9827   0.9958   0.9991
Neg Pred Value         0.9995   0.9979   0.9990   0.9972   0.9990
Prevalence             0.2845   0.1935   0.1743   0.1638   0.1839
Detection Rate         0.2841   0.1918   0.1735   0.1614   0.1830
Detection Prevalence   0.2856   0.1925   0.1766   0.1621   0.1832
Balanced Accuracy      0.9983   0.9952   0.9957   0.9923   0.9976
~~~~~~~

Since 99% accuracy was achieved on an out of sample testing set, the model seemed to be a good fit for the data. Next the model was run on the testing set provided and yielded the following results.

~~~~~~~
testPred <- predict(rfModel,newdata=test)
~~~~~~~
~~~~~~~
##B A B A A E D B A A B C B A E E A B B B
~~~~~~~